{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fully Connected Neural Network",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "UzxQAyAXJI0B",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UvCU5rHCJQWl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "URL_ENDPOINT = \"http://cs.mcgill.ca/~ksinha4/datasets/kaggle/\"\n",
        "\n",
        "train_x = np.loadtxt(URL_ENDPOINT+\"train_x.csv\", delimiter=\",\")\n",
        "train_y = np.loadtxt(URL_ENDPOINT+\"train_y.csv\", delimiter=\",\")\n",
        "test_x = np.loadtxt(URL_ENDPOINT+\"test_x.csv\", delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y2aUIyan7CJ7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "dYNZ9_2vSY7Y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#neural network implemented from the following tutorial http://neuralnetworksanddeeplearning.com/chap1.html\n",
        "\n",
        "\n",
        "class Network(object):\n",
        "\n",
        "    def __init__(self, layers):\n",
        "        \n",
        "        self.num_layers = len(layers)\n",
        "        self.layers = layers\n",
        "        self.bs = [np.random.randn(y, 1) for y in layers[1:]]\n",
        "        self.ws = [np.random.randn(y, x)\n",
        "                        for x, y in zip(layers[:-1], layers[1:])]\n",
        "\n",
        "    def feedforward(self, a):\n",
        "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
        "        for b, w in zip(self.bs, self.ws):\n",
        "            a = sigmoid(np.dot(w, a)+b)\n",
        "        return a\n",
        "    \n",
        "    #stochastic gradient descent\n",
        "    def SGD(self, training_data, epo, mini_batch_size, lr, reg, l2=True,\n",
        "            test_data=None):\n",
        "    \t  # optional test data which if provided will be evaluated against.\n",
        "        if test_data: n_test = len(test_data)\n",
        "        \n",
        "        n = len(training_data)\n",
        "        for j in xrange(epo):\n",
        "            random.shuffle(training_data)\n",
        "            mini_batches = [\n",
        "                training_data[k:k+mini_batch_size]\n",
        "                for k in xrange(0, n, mini_batch_size)]\n",
        "            for mini_batch in mini_batches:\n",
        "                self.update_mini_batch(mini_batch, lr, reg)\n",
        "            if test_data:\n",
        "                print \"Epoch {0}: {1} / {2}\".format(\n",
        "                    j, self.evaluate(test_data), n_test)\n",
        "            else:\n",
        "                print \"Epoch {0} complete\".format(j)\n",
        "\n",
        "    def update_mini_batch(self, mini_batch, eta, reg, l2=False):\n",
        "        # initialiize empty biases\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.bs]\n",
        "        # initialiize empty weights\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.ws]\n",
        "        for x, y in mini_batch:\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
        "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
        "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "        #conduct l2_regularization:\n",
        "        self.ws = [(1+reg)*w-(eta/len(mini_batch))*nw\n",
        "                        for w, nw in zip(self.ws, nabla_w)]\n",
        "        self.bs = [(1+reg)*b-(eta/len(mini_batch))*nb\n",
        "                       for b, nb in zip(self.bs, nabla_b)]\n",
        "          \n",
        "\n",
        "    def backprop(self, x, y):\n",
        "        #the respective arrays will contain the gradient for the cost function, and the\n",
        "        #indexes will function as the layer number.\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.bs]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.ws]\n",
        "        # feedforward\n",
        "        activation = x\n",
        "        activations = [x] # list to store all the activations, layer by layer\n",
        "        zs = [] # list to store all the z vectors, layer by layer\n",
        "        for b, w in zip(self.bs, self.ws):\n",
        "            z = np.dot(w, activation)+b\n",
        "            zs.append(z)\n",
        "            activation = sigmoid(z)\n",
        "            activations.append(activation)\n",
        "        # backward pass\n",
        "        delta = self.cost_derivative(activations[-1], y) * \\\n",
        "            sigmoid_prime(zs[-1])\n",
        "        nabla_b[-1] = delta\n",
        "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
        "        #iterating the layers backwards, in otherwords closer to the \n",
        "        for l in xrange(2, self.num_layers):\n",
        "            z = zs[-l]\n",
        "            sp = sigmoid_prime(z)\n",
        "            delta = np.dot(self.ws[-l+1].transpose(), delta) * sp\n",
        "            nabla_b[-l] = delta\n",
        "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
        "        return (nabla_b, nabla_w)\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        #returns the test results for neural network.\n",
        "        test_results = [(np.argmax(self.feedforward(x)), np.argmax(y))\n",
        "                        for (x, y) in test_data]\n",
        "        return sum(int(x == y) for (x, y) in test_results)\n",
        "\n",
        "    def cost_derivative(self, output_activations, y):\n",
        "        #returns the vector of partial derivative\n",
        "        return (output_activations-y)\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "    return sigmoid(z)*(1-sigmoid(z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3mE7oNQAhPEf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from scipy import ndimage\n",
        "from skimage.transform import resize\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VxLyk3AKgoHe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def find_largest_bounding_box(im):\n",
        "  # convert to binary image\n",
        "#   _, im = cv2.threshold(im,254,255,cv2.THRESH_BINARY)\n",
        "  im[im<255]=0\n",
        "  im[im==255]=1\n",
        "  \n",
        "  label_im, nb_labels = ndimage.label(im)\n",
        "  \n",
        "  # find largest connected component\n",
        "  sizes = ndimage.sum(im, label_im, range(nb_labels + 1))\n",
        "  mask_size = sizes < 4**2\n",
        "  remove_pixel = mask_size[label_im]\n",
        "  label_im[remove_pixel] = 0\n",
        "  labels = np.unique(label_im)\n",
        "  label_im = np.searchsorted(labels, label_im)\n",
        "\n",
        "  digits = ndimage.find_objects(label_im)\n",
        "  max_side = 0\n",
        "  max_ind = 0\n",
        "  for i in range(0,len(digits)):\n",
        "    bound = im[digits[i]]\n",
        "    if np.max(bound.shape) > max_side:\n",
        "      max_side = np.max(bound.shape)\n",
        "      max_ind = i\n",
        "\n",
        "  bound_rec = im[digits[max_ind]]\n",
        "  \n",
        "  # pad and resize\n",
        "  if bound_rec.shape[0] > bound_rec.shape[1]:\n",
        "    resize_short = round(24*bound_rec.shape[1]/bound_rec.shape[0])\n",
        "    bound_rec = resize(bound_rec, (24, resize_short), mode='reflect')\n",
        "    pad_before = (np.ceil((28 - resize_short)/2)).astype(int)\n",
        "    pad_after = (np.floor((28 - resize_short)/2)).astype(int)\n",
        "    bound_squ = np.pad(bound_rec,((2,2),(pad_before, pad_after)),'constant', constant_values=0)\n",
        "    \n",
        "  else:\n",
        "    resize_short = round(24*bound_rec.shape[0]/bound_rec.shape[1])\n",
        "    bound_rec = resize(bound_rec, (resize_short, 24), mode='reflect')\n",
        "    pad_before = (np.ceil((28 - resize_short)/2)).astype(int)\n",
        "    pad_after = (np.floor((28 - resize_short)/2)).astype(int)\n",
        "    bound_squ = np.pad(bound_rec,((pad_before, pad_after),(2,2)),'constant', constant_values=0)\n",
        "#   _, bound_squ = cv2.threshold(bound_squ,254,255,cv2.THRESH_BINARY)\n",
        "  bound_squ[bound_squ<1] = 0\n",
        "  \n",
        "  return bound_squ\n",
        "\n",
        "\n",
        "def preprocess(train):\n",
        "  prep = np.zeros((len(train),28,28))\n",
        "  for i in range(0,len(prep)):\n",
        "    prep[i] = find_largest_bounding_box(train[i].copy())\n",
        "  return prep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hZYLmYn1qXZ5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def vectorized_result(j):\n",
        "    #opposite of to_categorical\n",
        "    e = np.zeros((10, 1))\n",
        "    e[j] = 1.0\n",
        "    return e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "McZ2bvVWg-gU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "07938115-f621-4aca-8acc-7d9985e801a2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521738137143,
          "user_tz": 240,
          "elapsed": 83209,
          "user": {
            "displayName": "Abhinav Bhandari",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108370734082458731879"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# reshape to original data form\n",
        "x = train_x.reshape(-1, 64, 64)\n",
        "y = train_y.reshape(-1, 1) \n",
        "test = test_x.reshape(-1, 64, 64)\n",
        "\n",
        "prep_x = preprocess(x)\n",
        "#np.savetxt('prep_train_x.csv',prep_x.reshape(-1,28**2),delimiter=',')\n",
        "prep_test = preprocess(test)\n",
        "#np.savetxt('prep_test_x.csv',prep_test.reshape(-1,28**2),delimiter=',')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/scipy/ndimage/measurements.py:431: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  safe = ((np.issubdtype(dt, int) and dt.itemsize <= int_size) or\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9W9gIArxlNo7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#change the shape into a vector\n",
        "prep_x_2 = [x.reshape(784, 1) for x in prep_x]\n",
        "prep_x_2 = np.array(prep_x_2)\n",
        "t_y = np.array([vectorized_result(int(i[0])) for i in y])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RQhwUs34yjJX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "X0gx-v6X2Ir9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#code retreived from https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
        "def shuffle_in_unison(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
        "    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
        "    permutation = np.random.permutation(len(a))\n",
        "    for old_index, new_index in enumerate(permutation):\n",
        "        shuffled_a[new_index] = a[old_index]\n",
        "        shuffled_b[new_index] = b[old_index]\n",
        "    return shuffled_a, shuffled_b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lMFo55sJrz3U",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 50
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1697
        },
        "outputId": "6a872694-d868-41db-dd17-813427a6be1e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521745677253,
          "user_tz": 240,
          "elapsed": 284847,
          "user": {
            "displayName": "Abhinav Bhandari",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108370734082458731879"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "shuffle_train, shuffle_y = shuffle_in_unison(prep_x_2, t_y)\n",
        "#set network parameters here\n",
        "#the number of elements in the array of Network([arr]) is the number of layers, and the corresponding number is number of neurons in that layer. In otherwords, first layer has 784 neurons\n",
        "# and the last layer has 10 neurons.\n",
        "net = Network([784, 16, 10])\n",
        "net.SGD(zip(shuffle_train[:40000], shuffle_y[:40000]), 50, 200, 0.005, 0, test_data=zip(shuffle_train[40000:],shuffle_y[40000:]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "Epoch 0: 1008 / 10000\n",
            "4\n",
            "Epoch 1: 1048 / 10000\n",
            "4\n",
            "Epoch 2: 1056 / 10000\n",
            "4\n",
            "Epoch 3: 1081 / 10000\n",
            "4\n",
            "Epoch 4: 1131 / 10000\n",
            "4\n",
            "Epoch 5: 1153 / 10000\n",
            "4\n",
            "Epoch 6: 1182 / 10000\n",
            "4\n",
            "Epoch 7: 1205 / 10000\n",
            "4\n",
            "Epoch 8: 1230 / 10000\n",
            "4\n",
            "Epoch 9: 1261 / 10000\n",
            "4\n",
            "Epoch 10: 1290 / 10000\n",
            "4\n",
            "Epoch 11: 1306 / 10000\n",
            "4\n",
            "Epoch 12: 1332 / 10000\n",
            "4\n",
            "Epoch 13: 1343 / 10000\n",
            "4\n",
            "Epoch 14: 1356 / 10000\n",
            "4\n",
            "Epoch 15: 1369 / 10000\n",
            "4\n",
            "Epoch 16: 1369 / 10000\n",
            "4\n",
            "Epoch 17: 1378 / 10000\n",
            "4\n",
            "Epoch 18: 1385 / 10000\n",
            "4\n",
            "Epoch 19: 1398 / 10000\n",
            "4\n",
            "Epoch 20: 1401 / 10000\n",
            "4\n",
            "Epoch 21: 1391 / 10000\n",
            "4\n",
            "Epoch 22: 1385 / 10000\n",
            "0\n",
            "Epoch 23: 1382 / 10000\n",
            "0\n",
            "Epoch 24: 1381 / 10000\n",
            "0\n",
            "Epoch 25: 1382 / 10000\n",
            "0\n",
            "Epoch 26: 1384 / 10000\n",
            "0\n",
            "Epoch 27: 1386 / 10000\n",
            "0\n",
            "Epoch 28: 1394 / 10000\n",
            "0\n",
            "Epoch 29: 1406 / 10000\n",
            "0\n",
            "Epoch 30: 1412 / 10000\n",
            "0\n",
            "Epoch 31: 1415 / 10000\n",
            "0\n",
            "Epoch 32: 1419 / 10000\n",
            "0\n",
            "Epoch 33: 1419 / 10000\n",
            "0\n",
            "Epoch 34: 1425 / 10000\n",
            "0\n",
            "Epoch 35: 1428 / 10000\n",
            "0\n",
            "Epoch 36: 1427 / 10000\n",
            "0\n",
            "Epoch 37: 1426 / 10000\n",
            "0\n",
            "Epoch 38: 1429 / 10000\n",
            "0\n",
            "Epoch 39: 1432 / 10000\n",
            "0\n",
            "Epoch 40: 1436 / 10000\n",
            "0\n",
            "Epoch 41: 1443 / 10000\n",
            "0\n",
            "Epoch 42: 1445 / 10000\n",
            "0\n",
            "Epoch 43: 1452 / 10000\n",
            "0\n",
            "Epoch 44: 1456 / 10000\n",
            "0\n",
            "Epoch 45: 1457 / 10000\n",
            "0\n",
            "Epoch 46: 1467 / 10000\n",
            "0\n",
            "Epoch 47: 1468 / 10000\n",
            "0\n",
            "Epoch 48: 1470 / 10000\n",
            "0\n",
            "Epoch 49: 1480 / 10000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}